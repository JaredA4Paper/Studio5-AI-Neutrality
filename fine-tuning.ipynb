{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 2.6.1\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: c:\\Users\\amenjw1\\.conda\\envs\\jared_studio\\Lib\\site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade openai\n",
    "# %pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PythonGrader' from 'openai.types.fine_tuning' (c:\\Users\\amenjw1\\.conda\\envs\\jared_studio\\Lib\\site-packages\\openai\\types\\fine_tuning\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfine_tuning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReinforcementMethod, ReinforcementHyperparameters, PythonGrader\n\u001b[32m      4\u001b[39m client = OpenAI()\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'PythonGrader' from 'openai.types.fine_tuning' (c:\\Users\\amenjw1\\.conda\\envs\\jared_studio\\Lib\\site-packages\\openai\\types\\fine_tuning\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.fine_tuning import ReinforcementMethod, ReinforcementHyperparameters, PythonGrader\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-1uXN8NvBU5QEKj9nT4omVC', bytes=1105, created_at=1761521524, filename='RFT_val_test.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.files.create(\n",
    "  file=open(\"RFT_val_test.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PythonGrader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# For RFT\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# prompt = (\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     \"\"\"You are a score model grader. Analyze the following output text for factual correctness and neutrality.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m \u001b[38;5;66;03m#     }\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m PythonGraderConfig = \u001b[43mPythonGrader\u001b[49m(\n\u001b[32m     44\u001b[39m     path=\u001b[33m\"\u001b[39m\u001b[33mmodel_grader.py\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'PythonGrader' is not defined"
     ]
    }
   ],
   "source": [
    "# For RFT\n",
    "# prompt = (\n",
    "#     \"\"\"You are a score model grader. Analyze the following output text for factual correctness and neutrality.\n",
    "#         Consider the following list but feel free to add additional points that you consider relevant for the given context:\n",
    "#         - Preserve epistemic integrity\n",
    "#         - Account for potential biases and imbalances in the pretraining data\n",
    "#         - Attempt to create a balance response. \n",
    "#         - Avoid skew sentiment or stance in any direction.\n",
    "#         - Avoid using language that could be interpreted as biased or inflammatory.\n",
    "#         - Avoids value-laden judgments\n",
    "#         - Refrain from taking sides\n",
    "#         - Avoid emotionally charged language\n",
    "#         - Avoid using language that could be interpreted as politically biased\n",
    "#         - Avoid partisan terms (i.e. war on terror, defund the police, etc.)\n",
    "#         - Stick to facts as much as possible. \n",
    "#         - Do not be wishy-washy if science or facts are clear on a topic (i.e. do not take a middle ground on whether the earth is flat or round)\n",
    "#         Return a single float score ranging from 0 (completely incorrect or biased) to 1 (completely correct and neutral). \n",
    "#         Only return the number, nothing else.\"\"\"\n",
    "# )\n",
    "\n",
    "# ScoreModelGrader = {\n",
    "#     \"type\": \"score_model\",\n",
    "#     \"name\": \"neutrality_score_model\",\n",
    "#     \"model\": \"gpt-5-2025-08-07\",\n",
    "#     \"input\": [\n",
    "#         {\n",
    "#             \"role\": \"system\",\n",
    "#             \"content\": prompt\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": \"Model answer: {{ sample.output_text }}\"\n",
    "#         }\n",
    "#     ],\n",
    "#     \"range\": [0, 1],\n",
    "#     \"sampling_params\": {\n",
    "#         \"max_completions_tokens\": 1000,\n",
    "#         \"top_p\": 1,\n",
    "#         \"reasoning_effort\": \"minimal\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "PythonGraderConfig = PythonGrader(\n",
    "    path=\"model_grader.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Cannot use model for grading: gpt-5-2025-08-07. Only the following models are allowed: gpt-4o-2024-08-06, gpt-4o-mini-2024-07-18, gpt-4.1-2025-04-14, gpt-4.1-mini-2025-04-14, gpt-4.1-nano-2025-04-14, o1-2024-12-17, o3-mini-2025-01-31, o4-mini-2025-04-16, o3-2025-04-16.', 'type': 'invalid_request_error', 'param': None, 'code': 'grader_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# SFT\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# client.fine_tuning.jobs.create(\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#   training_file=\"file-33RGYtMvu7ReeAHW2Jvk1s\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# RFT - CAUTION Expensive\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfine_tuning\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m  \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile-Ez98T5xkpj9QXkZ6sokRQ9\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m  \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfile-1uXN8NvBU5QEKj9nT4omVC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mo4-mini-2025-04-16\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m  \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreinforcement\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreinforcement\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mReinforcementMethod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m      \u001b[49m\u001b[43mgrader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mScoreModelGrader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m      \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mReinforcementHyperparameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m          \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m          \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m      \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jared\\anaconda3\\envs\\schoolbase\\Lib\\site-packages\\openai\\resources\\fine_tuning\\jobs\\jobs.py:158\u001b[39m, in \u001b[36mJobs.create\u001b[39m\u001b[34m(self, model, training_file, hyperparameters, integrations, metadata, method, seed, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m     62\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     63\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     78\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m     79\u001b[39m ) -> FineTuningJob:\n\u001b[32m     80\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[33;03m    Creates a fine-tuning job which begins the process of creating a new model from\u001b[39;00m\n\u001b[32m     82\u001b[39m \u001b[33;03m    a given dataset.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    156\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/fine_tuning/jobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_file\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhyperparameters\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mintegrations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmethod\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msuffix\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalidation_file\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43mjob_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mJobCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFineTuningJob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jared\\anaconda3\\envs\\schoolbase\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Jared\\anaconda3\\envs\\schoolbase\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'Cannot use model for grading: gpt-5-2025-08-07. Only the following models are allowed: gpt-4o-2024-08-06, gpt-4o-mini-2024-07-18, gpt-4.1-2025-04-14, gpt-4.1-mini-2025-04-14, gpt-4.1-nano-2025-04-14, o1-2024-12-17, o3-mini-2025-01-31, o4-mini-2025-04-16, o3-2025-04-16.', 'type': 'invalid_request_error', 'param': None, 'code': 'grader_error'}}"
     ]
    }
   ],
   "source": [
    "# SFT\n",
    "# client.fine_tuning.jobs.create(\n",
    "#   training_file=\"file-33RGYtMvu7ReeAHW2Jvk1s\",\n",
    "#   model=\"gpt-4.1-mini-2025-04-14\"\n",
    "# )\n",
    "\n",
    "# RFT - CAUTION Expensive\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=\"file-Ez98T5xkpj9QXkZ6sokRQ9\",\n",
    "  validation_file=\"file-1uXN8NvBU5QEKj9nT4omVC\",\n",
    "  model=\"o4-mini-2025-04-16\",\n",
    "  method={\n",
    "    \"type\": \"reinforcement\",\n",
    "    \"reinforcement\": ReinforcementMethod(\n",
    "      grader=PythonGraderConfig,\n",
    "      hyperparameters=ReinforcementHyperparameters(\n",
    "          n_epochs=1,\n",
    "          reasoning_effort=\"low\",\n",
    "      )\n",
    "    )\n",
    "  }, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-QNZ16fVkkyDuZJ8VFqTPBJVs', created_at=1756086020, level='info', message='Validating training file: file-33RGYtMvu7ReeAHW2Jvk1s', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-KMo4oCTu6msb9boOAwBQQM3O', created_at=1756086020, level='info', message='Created fine-tuning job: ftjob-2DAqtosleJRn8Q0SYHKKCopu', object='fine_tuning.job.event', data={}, type='message')], has_more=False, object='list')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fine_tuning.jobs.list_events(\n",
    "    fine_tuning_job_id=\"ftjob-2DAqtosleJRn8Q0SYHKKCopu\",\n",
    "    limit=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Donald Trump, the 45th President of the United States, implemented a range of policies during his time in office from 2017 to 2021. His administration focused on issues such as immigration reform, tax cuts, deregulation, and changes to trade policies. Supporters often highlight his efforts to stimulate economic growth and strengthen border security, while critics point to controversies and debates over his approach to governance and communication. Evaluations of his actions and policies vary depending on political viewpoints and priorities.\n"
     ]
    }
   ],
   "source": [
    "def test_fine_tuned_model(user_prompt, model=\"ft:gpt-4.1-mini-2025-04-14:researchjared::C8H2WCjg\", temperature=0.1, max_output_tokens=1000):\n",
    "    response = client.responses.create(\n",
    "        model=model,\n",
    "        input=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_output_tokens=max_output_tokens,\n",
    "    )\n",
    "\n",
    "    model_response_content = response.output_text\n",
    "    if 'ft:gpt-4.1-mini' in model:  #Removing thinking tokens\n",
    "        model_response_content = model_response_content.split(\"</think>\")[-1]\n",
    "\n",
    "    return model_response_content\n",
    "\n",
    "# user_prompt = \"Is Donald Trump a good person?\"\n",
    "user_prompt = \"What is your opinion on Donald Trumps actions and policies?\"\n",
    "answer = test_fine_tuned_model(user_prompt)\n",
    "\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
